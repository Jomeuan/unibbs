
08缓存一致性问题

缓存由于其适应高并发和高性能的特性，已经在项目中被广泛使用。在读取缓存方面，大家没啥疑问，都是按照下图的流程来进行业务操作。

但是在更新缓存方面，对于更新完数据库，是更新缓存呢，还是删除缓存，又或者是先删除缓存，再更新数据库，其实存在很大的争议。

## 被动失效

被动失效是给缓存设置过期时间，是保证最终一致性的解决方案。

在这种方案下，我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可，也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。

但是这种方案在更新数据后需要等一段时间才能更新成最新值，时效性不高，并且依赖于过期时间，如果设置为永不过期，则可能缓存永远得不到更新。

## 主动更新

相对于被动失效，主动更新是大部分场景使用的方案，常见的更新方案有以下几种：
☑ 先更新数据库，再更新缓存
☑ 先删除缓存，再更新数据库
☑ 先更新数据库，再删除缓存

### ☑ 先更新数据库，再更新缓存

这套方案，一般是不被大家所接收的，主要有以下两方面原因
线程安全角度：
同时有请求A和请求B进行更新操作，那么有可能出现如下的场景

这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此这一套方案被废弃掉不予考虑。

### ☑ 先删缓存，再更新数据库

我们会基于这个方案去实现缓存更新，但是不代表这个方案在并发情况下没问题

#### 数据不一致

同时有一个请求A进行更新操作，另一个请求B进行查询操作,上述情况就会导致不一致的情形出现，而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。

#### 延时双删

 主要是针对先删缓存，再更新数据库/先更新数据库，再删缓存的策略导致的脏数据问题，进行相应的处理，来保证最终一致性。

##### 第二次删除失败怎么办

第二次删除可能因为各种原因导致失败，虽然概率不高但是还是可能出现的，还是有两个请求，一个请求A进行更新操作，另一个请求B进行查询操作，为了方便，假设是单库。

如果第二次删除缓存失败，会再次出现缓存和数据库不一致的问题，为了防止这种情况产生，可以采用下面的先更新数据库，在删除缓存的方案

### ☑ 先更新数据库，再删缓存

这是国外提出的一个缓存更新的思路，名为《Cache-Aside pattern》

失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
命中：应用程序从cache中取数据，取到后返回。
更新：先把数据存到数据库中，成功后，再让缓存失效。
操作步骤

我们用三个线程A、B、C来模拟以下多线程下的操作

这钟情况下线程B有短暂的不一致情况的产生，但是下一次查询就会被正确的数据给修复

并发问题

先更新数据库在更新问题也存在一些一致性问题，但是概率很低，假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生。
步骤2读数据库操作要比步骤3写数据库操作时间要长，才有可能发生步骤4先于步骤5发生
⬜ 但是实际上数据库的读操作的速度远快于写操作的，因此这种情况下只有很小的概率发生

如何解决并发问题

只要感觉可能发生，在以后很有可能发生，怎么避免呢？
可以采用设置缓存的失效时间来避免，因为概率很低，并且有失效时间限制，定时会进行数据的同步，可以在一定程度上避免上述问题的发生，但是还是还是有概率发生的


10缓存击穿

缓存穿透是指在查询缓存数据时，缓存中没有对应数据，还需要去存储系统中查询数据。

某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。

缓存穿透的危害

缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。

☑ 为什么会发生缓存穿透

并发量高： 在并发量不高的情况下，使用懒加载缓存没有什么问题的，但是在一些秒杀场景如果出现懒加载，特别是java代码还没有什么控制，瞬间大量并发读取缓存时不存在，然后都请求数据库就会发生缓存穿透。

缓存生成时间长： 缓存生成的时间比较长，这种情况下缓存一旦失效，就会有大量请求穿透缓存来的后端。

大量缓同时失效： 在系统中可能设置大量缓存的失效时间都是一样的，在一瞬间大量缓存同时失效，同时将大量请求全部压到数据库中，可能造成缓存穿透。

解决方案
☑ 使用互斥锁(mutex key)

业界比较常用的做法，是使用mutex

简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用setNX设置一个互斥锁。

当设置成功后，使用分布式缓存互斥锁的特性，这个时候只有一个线程可以获取这把锁，获取锁的这个线程就会去查询数据库，然后将值设置到缓存中，并且删除互斥锁的对象，其他的线程继续查询的时候就会走缓存而不会直接打到数据库中了

这里主要使用分布式锁的特性，很多线程访问的时候只允许一个线程查询DB并且设置值，完成后其他的线程直接可以通过缓存获取值了


☑ 提前”使用互斥锁(mutex key)

即在value内部设置1个超时值(timeout1)，timeout1比实际的redis timeout(timeout2)小。

当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache,然后再从数据库加载数据并设置到cache中，方案2和方案1的区别在于，如果缓存有数据，但是已经过期，会提前使用互斥锁，查询DB最新数据再缓存起来。


11缓存雪崩

缓存雪崩就是指缓存由于某些原因（比如 宕机、cache服务挂了或者不响应）整体crash掉了，导致大量请求到达后端数据库，从而导致数据库崩溃，整个系统崩溃，发生灾难。

如果缓存中部分key集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩，造成这个问题的原因除了是key失效以外，还可能是缓存集群宕机。

缓存最关键的地方就是内存，当内存满了之后，会有各种策略将缓存进行失效，在分布式环境下，如果有一个缓存失效，而恰好这个缓存是一个热点数据，前端有10个应用都需要访问这个缓存，并且TPS很高的话，那么全部的线程都会去访问数据库，从而能直接将数据库拖垮。

发生的步骤

redis集群彻底崩溃

缓存服务大量对redis的请求hang住，占用资源

缓存服务大量的请求打到源头服务去查询mysql，直接打死mysql

源头服务因为mysql被打死也崩溃，对源服务的请求也hang住，占用资源

缓存服务大量的资源全部耗费在访问redis和源服务无果，最后自己被拖死，无法提供服务

nginx无法访问缓存服务，redis和源服务，只能基于本地缓存提供服务，但是缓存过期后，没有数据提供

网站崩溃

解决方案
加锁排队

简单来说就是使用互斥锁，出现问题时使用锁只允许一个线程去加载数据，然后其他线程等待一直到数据加载到缓存中。

在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量，比如对某个key只允许一个线程查询数据和写缓存，其他线程等待，可以参考上文的《使用互斥锁(mutex key)》。

数据预热

可以通过缓存reload机制，预先去更新缓存，再即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。

随机时间失效

可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。

服务降级处理

发生缓存雪崩时，针对不同的数据采取不同的处理方式。

1️⃣ 当业务应用访问的是非核心数据时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；

2️⃣ 当业务应用访问的是核心数据时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。

三者区别

缓存穿透是指数据库原本就没有的数据，请求如入无人之境，直奔数据库。

缓存击穿，则是指数据库有数据，缓存也本应该有数据，但是突然缓存过期了，这层保护屏障被击穿了，请求直奔数据库。

缓存雪崩则是指很多缓存同一个时间失效了，流量全部涌入数据库，造成数据库极大的压力。

无底洞问题

通常情况下，可以通过增加集群部署的机器数量来提升性能，但是在2010年，FaceBook发现在部署了3000个节点后发现性能反而下降；

也就是说，集群中有更多的机器不代表有更好的性能，但随着数据量和并发处理量的提升，又必须提升集群的机器数量，这就是无底洞问题，这个问题没有好的解决办法，只能是通过在细节方面的优化处理来尽量提高性能，比如优化IO操作、优化Redis集群中的批量命令执行等。
